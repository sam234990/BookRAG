# configs/default.yaml

pdf_path: TODO
save_path: TODO

llm:
  model_name: Qwen/Qwen3-8B-AWQ
  api_key: openai
  api_base: http://localhost:8003/v1
  backend: openai
  max_tokens: 5000
  temperature: 0.1
  frequency_penalty: 0.0
  presence_penalty: 0.0
  max_workers: 8


vlm:
  model_name: Qwen2-5-VL
  api_key: openai
  api_base: http://localhost:8000/v1
  temperature: 0.1
  max_tokens: 6000
  backend: gpt

index:
  chunk_size: 512
  overlap: 50

mineru:
  backend: vlm-sglang-client
  method: vlm
  server_url: http://localhost:30000
  lang: en

tree:
  node_keywords: True
  node_summary: True

graph:
  extractor_type: "llm"
  local_model_name: "en_core_web_sm"
  image_description_force: True
  max_gleaning: 0
  refine_type: "basic"
  embedding_config:
    model_name: Qwen3-Embedding-0.6B
    backend: openai
    max_length: 4096
    device: "cuda:2"
    api_base: "http://localhost:8007/v1"
  reranker_config:
    model_name: Qwen3-Reranker-4B
    max_length: 4096
    device: "cuda:2"
    backend: vllm
    api_base: "http://localhost:8011/v1"


vdb:
  mm_embedding: True
  vdb_dir_name: "Tree_vdb"
  collection_name: "TreeVDB"
  embedding_config:
    model_name: Alibaba-NLP/gme-Qwen2-VL-2B-Instruct
    device: "cuda:1"

rag_force_reprocess: False

rag:
  strategy: gbc
  varient: wo_er
  topk: 10
  sim_threshold: 0.3
  select_depth: 2
  max_retry: 2
  reranker_config:
    model_name: Qwen3-Reranker-4B
    max_length: 4096
    device: "cuda:7"
    backend: vllm
    api_base: "http://localhost:8011/v1"
  mm_reranker_config:
    model_name: Alibaba-NLP/gme-Qwen2-VL-2B-Instruct
    device: "cuda:2"
